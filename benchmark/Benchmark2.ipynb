{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vot0dtKG9UnJ"
   },
   "source": [
    "# Benchmarking the performance of Pelican part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02nV9tRM9c_v"
   },
   "source": [
    "## Dataset\n",
    "[ImageNet](https://www.kaggle.com/c/imagenet-object-localization-challenge/overview)\n",
    "Using this [script](https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh) to prepare the data first. Then train it using ResNet50.\n",
    "\n",
    "## Hardware\n",
    "Google Colab T4 GPU with high RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXPgW9c53Bqf"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "u_k8XCG8xKMv"
   },
   "outputs": [],
   "source": [
    "!pip install torchdata\n",
    "!pip install pelicanfs fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-stSDqOxVa9",
    "outputId": "d518d021-9732-4cd2-9baf-9f67b3d9fcb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZiHA8yZqzGJs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import fsspec\n",
    "from pelicanfs.core import PelicanFileSystem\n",
    "import time\n",
    "from PIL import Image\n",
    "from fsspec.implementations.local import LocalFileSystem\n",
    "from torchvision.datasets import VisionDataset\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class RemoteImageFolder(VisionDataset):\n",
    "\n",
    "    def __init__(self, root,transform=None, target_transform=None):\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "        if os.path.isdir(root):\n",
    "            self._init_local(root)\n",
    "        else:\n",
    "            self._init_remote(root)\n",
    "\n",
    "    def _init_local(self, root):\n",
    "        print(f\"Initializing local dataset from {root}\")\n",
    "        self.root = root\n",
    "        self.fs = LocalFileSystem()\n",
    "        self.classes = sorted(os.listdir(root))\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        self.imgs = self._make_dataset_local()\n",
    "\n",
    "    def _init_remote(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.fs = PelicanFileSystem(\"pelican://osg-htc.org\")\n",
    "\n",
    "        self.classes = sorted([item['name'] for item in self.fs.ls(root)])\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "\n",
    "        self.imgs = self._make_dataset_remote()\n",
    "\n",
    "    def _make_dataset_local(self):\n",
    "        images = []\n",
    "        for class_idx, cls_name in enumerate(self.classes):\n",
    "            class_path = os.path.join(self.root, cls_name)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_name = img_name.lower()\n",
    "                if img_name.endswith('.jpg') or img_name.endswith('.jpeg') or img_name.endswith('.png'):\n",
    "                    img_path = os.path.join(class_path, img_name)\n",
    "                    images.append((img_path, class_idx))\n",
    "        return images\n",
    "\n",
    "    def _make_dataset_remote(self):\n",
    "        images = []\n",
    "        for class_idx, cls_name in enumerate(self.classes):\n",
    "            class_path = os.path.join(self.root, cls_name)\n",
    "            files = self.fs.ls(class_path)\n",
    "            for item in files:\n",
    "                img_path = item['name']\n",
    "                if img_path.lower().endswith('.jpg') or img_path.lower().endswith('.jpeg') or img_path.lower().endswith('.png'):\n",
    "                    images.append((img_path, class_idx))\n",
    "        print(\"len(images): \", len(images))\n",
    "        return images\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, target = self.imgs[index]\n",
    "        if isinstance(self.fs, PelicanFileSystem):\n",
    "            with self.fs.open(img_path, 'rb') as f:\n",
    "                img = Image.open(f).convert('RGB')\n",
    "        else:\n",
    "            img = read_image(img_path)\n",
    "            img = transforms.ToPILImage()(img)\n",
    "\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FR2_mRYOzoNj",
    "outputId": "fc9c0373-c92d-409d-b508-8cdcf3e73fdb"
   },
   "outputs": [
    {
     "ename": "BadDirectorResponse",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadDirectorResponse\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6m/x_pssmzs08z8fzh7hs3yj5ph0000gn/T/ipykernel_53372/3089084041.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Load the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemoteImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_trainfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRemoteImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_valfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6m/x_pssmzs08z8fzh7hs3yj5ph0000gn/T/ipykernel_53372/3227569021.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6m/x_pssmzs08z8fzh7hs3yj5ph0000gn/T/ipykernel_53372/3227569021.py\u001b[0m in \u001b[0;36m_init_remote\u001b[0;34m(self, root, transform)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPelicanFileSystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pelican://osg-htc.org\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFSTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mcoro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pelicanfs/core.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0mdataUrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dirlist_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataUrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pelicanfs/core.py\u001b[0m in \u001b[0;36mget_dirlist_url\u001b[0;34m(self, fileloc)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PROPFIND'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'Link'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mBadDirectorResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mdirlist_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_metalink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdirlist_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadDirectorResponse\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import torch.multiprocessing as mp\n",
    "import time\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  # Ensure ToTensor is included\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),  # Ensure ToTensor is included\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Define the Pelican paths\n",
    "trainfile_path = \"/chtc/PUBLIC/hzhao292/ILSVRC/Data/CLS-LOC/train\"\n",
    "valfile_path = \"/chtc/PUBLIC/hzhao292/ILSVRC/Data/CLS-LOC/val\"\n",
    "\n",
    "dev_trainfile_path = \"/chtc/PUBLIC/hzhao292/ImageNetMini/train\"\n",
    "dev_valfile_path = \"/chtc/PUBLIC/hzhao292/ImageNetMini/val\"\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = RemoteImageFolder(root=dev_trainfile_path, transform=train_transforms)\n",
    "val_dataset = RemoteImageFolder(root=dev_valfile_path, transform=val_transforms)\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AAROVPOIsyNh",
    "outputId": "ffd8e6ef-919e-4260-e86a-b0f93a6452e4"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 51.7MB/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Epoch 1 started.\n",
      "Batch  10\n",
      "Batch  20\n",
      "Batch  30\n",
      "Batch  40\n",
      "Batch  50\n",
      "Batch  60\n",
      "Batch  70\n",
      "Batch  80\n",
      "Batch  90\n",
      "Batch  100\n",
      "Batch  110\n",
      "Batch  120\n",
      "Batch  130\n",
      "Batch  140\n",
      "Batch  150\n",
      "Batch  160\n",
      "Batch  170\n",
      "Batch  180\n",
      "Batch  190\n",
      "Batch  200\n",
      "Batch  210\n",
      "Batch  220\n",
      "Batch  230\n",
      "Batch  240\n",
      "Batch  250\n",
      "Batch  260\n",
      "Batch  270\n",
      "Batch  280\n",
      "Batch  290\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 1.1407\n",
      "Epoch 1/10, Validation Loss: 0.6926, Accuracy: 0.7809, Time Taken: 1138.80 seconds\n",
      "Epoch 2 started.\n",
      "Batch  10\n",
      "Batch  20\n",
      "Batch  30\n",
      "Batch  40\n",
      "Batch  50\n",
      "Batch  60\n",
      "Batch  70\n",
      "Batch  80\n",
      "Batch  90\n",
      "Batch  100\n",
      "Batch  110\n",
      "Batch  120\n",
      "Batch  130\n",
      "Batch  140\n",
      "Batch  150\n",
      "Batch  160\n",
      "Batch  170\n",
      "Batch  180\n",
      "Batch  190\n",
      "Batch  200\n",
      "Batch  210\n",
      "Batch  220\n",
      "Batch  230\n",
      "Batch  240\n",
      "Batch  250\n",
      "Batch  260\n",
      "Batch  270\n",
      "Batch  280\n",
      "Batch  290\n",
      "Epoch 2/10, Training Loss: 0.8152\n",
      "Epoch 2/10, Validation Loss: 0.6254, Accuracy: 0.8020, Time Taken: 1113.87 seconds\n",
      "Epoch 3 started.\n",
      "Batch  10\n",
      "Batch  20\n",
      "Batch  30\n",
      "Batch  40\n",
      "Batch  50\n",
      "Batch  60\n",
      "Batch  70\n",
      "Batch  80\n",
      "Batch  90\n",
      "Batch  100\n",
      "Batch  110\n",
      "Batch  120\n",
      "Batch  130\n",
      "Batch  140\n",
      "Batch  150\n",
      "Batch  160\n",
      "Batch  170\n",
      "Batch  180\n",
      "Batch  190\n",
      "Batch  200\n",
      "Batch  210\n",
      "Batch  220\n",
      "Batch  230\n",
      "Batch  240\n",
      "Batch  250\n",
      "Batch  260\n",
      "Batch  270\n",
      "Batch  280\n",
      "Batch  290\n",
      "Epoch 3/10, Training Loss: 0.7164\n",
      "Epoch 3/10, Validation Loss: 0.4831, Accuracy: 0.8522, Time Taken: 1074.37 seconds\n",
      "Epoch 4 started.\n",
      "Batch  10\n",
      "Batch  20\n",
      "Batch  30\n",
      "Batch  40\n",
      "Batch  50\n",
      "Batch  60\n",
      "Batch  70\n",
      "Batch  80\n",
      "Batch  90\n",
      "Batch  100\n",
      "Batch  110\n",
      "Batch  120\n",
      "Batch  130\n",
      "Batch  140\n",
      "Batch  150\n",
      "Batch  160\n",
      "Batch  170\n",
      "Batch  180\n",
      "Batch  190\n",
      "Batch  200\n",
      "Batch  210\n",
      "Batch  220\n",
      "Batch  230\n",
      "Batch  240\n",
      "Batch  250\n",
      "Batch  260\n",
      "Batch  270\n",
      "Batch  280\n",
      "Batch  290\n",
      "Epoch 4/10, Training Loss: 0.6283\n",
      "Epoch 4/10, Validation Loss: 0.4641, Accuracy: 0.8548, Time Taken: 1094.85 seconds\n",
      "Epoch 5 started.\n",
      "Batch  10\n",
      "Batch  20\n",
      "Batch  30\n",
      "Batch  40\n",
      "Batch  50\n",
      "Batch  60\n",
      "Batch  70\n",
      "Batch  80\n",
      "Batch  90\n",
      "Batch  100\n",
      "Batch  110\n",
      "Batch  120\n",
      "Batch  130\n",
      "Batch  140\n",
      "Batch  150\n",
      "Batch  160\n",
      "Batch  170\n",
      "Batch  180\n",
      "Batch  190\n",
      "Batch  200\n",
      "Batch  210\n",
      "Batch  220\n",
      "Batch  230\n",
      "Batch  240\n",
      "Batch  250\n",
      "Batch  260\n",
      "Batch  270\n",
      "Batch  280\n",
      "Batch  290\n",
      "Epoch 5/10, Training Loss: 0.6057\n",
      "Epoch 5/10, Validation Loss: 0.4219, Accuracy: 0.8683, Time Taken: 1086.80 seconds\n",
      "Epoch 6 started.\n",
      "Batch  10\n",
      "Batch  20\n",
      "Batch  30\n",
      "Batch  40\n",
      "Batch  50\n",
      "Batch  60\n",
      "Batch  70\n",
      "Batch  80\n",
      "Batch  90\n",
      "Batch  100\n",
      "Batch  110\n",
      "Batch  120\n",
      "Batch  130\n",
      "Batch  140\n",
      "Batch  150\n",
      "Batch  160\n",
      "Batch  170\n",
      "Batch  180\n",
      "Batch  190\n",
      "Batch  200\n",
      "Batch  210\n",
      "Batch  220\n",
      "Batch  230\n",
      "Batch  240\n",
      "Batch  250\n",
      "Batch  260\n",
      "Batch  270\n",
      "Batch  280\n",
      "Batch  290\n",
      "Epoch 6/10, Training Loss: 0.5727\n",
      "Epoch 6/10, Validation Loss: 0.3740, Accuracy: 0.8792, Time Taken: 1094.54 seconds\n",
      "Epoch 7 started.\n",
      "Batch  10\n",
      "Batch  20\n",
      "Batch  30\n",
      "Batch  40\n",
      "Batch  50\n",
      "Batch  60\n",
      "Batch  70\n",
      "Batch  80\n",
      "Batch  90\n",
      "Batch  100\n",
      "Batch  110\n",
      "Batch  120\n",
      "Batch  130\n",
      "Batch  140\n",
      "Batch  150\n",
      "Batch  160\n",
      "Batch  170\n",
      "Batch  180\n",
      "Batch  190\n",
      "Batch  200\n",
      "Batch  210\n",
      "Batch  220\n",
      "Batch  230\n",
      "Batch  240\n",
      "Batch  250\n",
      "Batch  260\n",
      "Batch  270\n",
      "Batch  280\n",
      "Batch  290\n",
      "Epoch 7/10, Training Loss: 0.5550\n",
      "Epoch 7/10, Validation Loss: 0.4256, Accuracy: 0.8591, Time Taken: 1119.60 seconds\n",
      "Epoch 8 started.\n",
      "Batch  10\n",
      "Batch  20\n",
      "Batch  30\n",
      "Batch  40\n",
      "Batch  50\n",
      "Batch  60\n",
      "Batch  70\n",
      "Batch  80\n",
      "Batch  90\n",
      "Batch  100\n",
      "Batch  110\n",
      "Batch  120\n",
      "Batch  130\n",
      "Batch  140\n",
      "Batch  150\n",
      "Batch  160\n",
      "Batch  170\n",
      "Batch  180\n",
      "Batch  190\n",
      "Batch  200\n",
      "Batch  210\n",
      "Batch  220\n",
      "Batch  230\n",
      "Batch  240\n",
      "Batch  250\n",
      "Batch  260\n",
      "Batch  270\n",
      "Batch  280\n",
      "Batch  290\n",
      "Epoch 8/10, Training Loss: 0.5281\n",
      "Epoch 8/10, Validation Loss: 0.3873, Accuracy: 0.8785, Time Taken: 1090.34 seconds\n",
      "Epoch 9 started.\n",
      "Batch  10\n",
      "Batch  20\n",
      "Batch  30\n",
      "Batch  40\n",
      "Batch  50\n",
      "Batch  60\n",
      "Batch  70\n",
      "Batch  80\n",
      "Batch  90\n",
      "Batch  100\n",
      "Batch  110\n",
      "Batch  120\n",
      "Batch  130\n",
      "Batch  140\n",
      "Batch  150\n",
      "Batch  160\n",
      "Batch  170\n",
      "Batch  180\n",
      "Batch  190\n",
      "Batch  200\n",
      "Batch  210\n",
      "Batch  220\n",
      "Batch  230\n",
      "Batch  240\n",
      "Batch  250\n",
      "Batch  260\n",
      "Batch  270\n",
      "Batch  280\n",
      "Batch  290\n",
      "Epoch 9/10, Training Loss: 0.5102\n",
      "Epoch 9/10, Validation Loss: 0.3713, Accuracy: 0.8897, Time Taken: 1142.84 seconds\n",
      "Epoch 10 started.\n",
      "Batch  10\n",
      "Batch  20\n",
      "Batch  30\n",
      "Batch  40\n",
      "Batch  50\n",
      "Batch  60\n",
      "Batch  70\n",
      "Batch  80\n",
      "Batch  90\n",
      "Batch  100\n",
      "Batch  110\n",
      "Batch  120\n",
      "Batch  130\n",
      "Batch  140\n",
      "Batch  150\n",
      "Batch  160\n",
      "Batch  170\n",
      "Batch  180\n",
      "Batch  190\n",
      "Batch  200\n",
      "Batch  210\n",
      "Batch  220\n",
      "Batch  230\n",
      "Batch  240\n",
      "Batch  250\n",
      "Batch  260\n",
      "Batch  270\n",
      "Batch  280\n",
      "Batch  290\n",
      "Epoch 10/10, Training Loss: 0.4883\n",
      "Epoch 10/10, Validation Loss: 0.3427, Accuracy: 0.8917, Time Taken: 1141.83 seconds\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(train_dataset.classes))\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and validation loop\n",
    "num_epochs = 10\n",
    "\n",
    "print(\"Training started.\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch\", epoch+1, \"started.\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    i=0\n",
    "    for inputs, labels in train_loader:\n",
    "        i+=1\n",
    "        if i%10==0:\n",
    "            print(\"Batch \", i)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}, Time Taken: {time_taken:.2f} seconds\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsA1D8Lxzpm8"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet50_imagenet.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pssz8JOXHBFW"
   },
   "source": [
    "## Using DataPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbP8kuHUkpdA"
   },
   "outputs": [],
   "source": [
    "# Streaming version\n",
    "import fsspec\n",
    "from pelicanfs.core import PelicanFileSystem, PelicanMap, OSDFFileSystem\n",
    "zipfilepath = \"pelican://osg-htc.org/chtc/PUBLIC/hzhao292/imagenet-object-localization-challenge.zip\"\n",
    "trainfile_path = \"/chtc/PUBLIC/hzhao292/ILSVRC/Data/CLS-LOC/train\"\n",
    "valfile_path = \"pelican://osg-htc.org/chtc/PUBLIC/hzhao292/ILSVRC/Data/CLS-LOC/val\"\n",
    "fs = fsspec.filesystem('pelican')\n",
    "pfs = PelicanFileSystem('pelican://osg-htc.org/')\n",
    "\n",
    "# dp2 = IterableWrapper([zipfilepath])  \\\n",
    "#         .open_files_by_fsspec(mode=\"rb\") \\\n",
    "#         .load_from_zip()\n",
    "# for path, filestream in dp2:\n",
    "#     print(path, filestream)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "kBsPELVOHA12",
    "outputId": "c5a247f7-569d-4bb8-e25a-91d21506e667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.RemoteImageDataPipe'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-91da17d57dd1>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Create DataLoaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_datapipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_datapipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import fsspec\n",
    "import torch\n",
    "torch.utils.data.datapipes.utils.common.DILL_AVAILABLE = torch.utils._import_utils.dill_available()\n",
    "# Need add this line if run in google colab, or it will cause error\n",
    "# torch.utils.data.datapipes.utils.common.DILL_AVAILABLE = torch.utils._import_utils.dill_available()\n",
    "from torchdata.datapipes.iter import IterableWrapper, FileOpener\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "from torchdata.datapipes.iter import IterDataPipe\n",
    "from torchdata import dataloader2 as DataLoader2\n",
    "\n",
    "class RemoteImageDataPipe(IterDataPipe):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.fs = fsspec.filesystem('pelican')\n",
    "        self.files = self.fs.ls(root)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file in self.files:\n",
    "            with self.fs.open(file, 'rb') as f:\n",
    "                img = read_image(f).convert('RGB')\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                yield img\n",
    "\n",
    "# Define transformations for training and validation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "/Users/a/Documents/2024summerintern/IntegratePelicanwithPytorch/benchmark/Benchmark2.ipynb\n",
    "# Define the S3 paths\n",
    "trainfile_path = \"/chtc/PUBLIC/hzhao292/ILSVRC/Data/CLS-LOC/train\"\n",
    "valfile_path = \"/chtc/PUBLIC/hzhao292/ILSVRC/Data/CLS-LOC/val\"\n",
    "\n",
    "# Create DataPipes for training and validation datasets\n",
    "train_datapipe = RemoteImageDataPipe(root=trainfile_path, transform=train_transforms)\n",
    "val_datapipe = RemoteImageDataPipe(root=valfile_path, transform=val_transforms)\n",
    "print(type(train_datapipe))\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader2(train_datapipe, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader2(val_datapipe, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "for i in train_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
