{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vot0dtKG9UnJ"
   },
   "source": [
    "# Benchmarking the performance of Pelican part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02nV9tRM9c_v"
   },
   "source": [
    "## Dataset\n",
    "[ImageNet](https://www.kaggle.com/c/imagenet-object-localization-challenge/overview)\n",
    "\n",
    "Using this [script](https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh) to prepare the data first. Then train it using ResNet50.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "If you want to download the dataset in our Pelican Origin, do\n",
    "\n",
    "```\n",
    "pelican object get pelican://osg-htc.org/chtc/PUBLIC/hzhao292/<filename> <destination>\n",
    "```\n",
    "\n",
    "Filename and size listed:\n",
    "\n",
    "\n",
    "| File     | Size | Description |\n",
    "| :----------- | :-----------: | :---------|\n",
    "| ImageNet.zip     |156G   | The zip version of full ImageNet dataset |\n",
    "| ImageNet|161G |Decompressed version of the upper one, data in/train and /val|\n",
    "| ImageNetMini.tgz|1.5G| The smaller version, subset of ImageNet |\n",
    "| ImageNetMini  | 1.5G  | Folder of smaller version ImageNet dataset, go /train or /val for classified images|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Hardware\n",
    "GPU:                   NVIDIA Tesla V100\n",
    "\n",
    "RAM:                   256G\n",
    "\n",
    "Architecture:          x86_64\n",
    "\n",
    "CPU op-mode(s):        32-bit, 64-bit\n",
    "\n",
    "Byte Order:            Little Endian\n",
    "\n",
    "CPU(s):                40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_k8XCG8xKMv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision.datasets import VisionDataset\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import fsspec\n",
    "from pelicanfs.core import PelicanFileSystem\n",
    "from fsspec.implementations.local import LocalFileSystem\n",
    "from fsspec.implementations.cached import WholeFileCacheFileSystem\n",
    "\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import zipfile\n",
    "from remote_image_folder import RemoteImageFolder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mp.set_start_method('spawn', force=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to use the `dev_trainfile_path` and `dev_valfile_path`. They are the smaller version of ImageNet dataset, which is 1.5G totally. \n",
    "\n",
    "Change the path to `trainfile_path` and `valfile_path` passed to RemoteImageFolder if you want to test the 150G whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define path, transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local datas path\n",
    "local_trainfile_path = \"ImageNetMini/train\"\n",
    "local_valfile_path = \"ImageNetMini/val\"\n",
    "\n",
    "# Define the Pelican paths\n",
    "trainfile_path = \"/chtc/PUBLIC/hzhao292/ImageNet/train\"\n",
    "valfile_path = \"/chtc/PUBLIC/hzhao292/ImageNet/val\"\n",
    "\n",
    "dev_trainfile_path = \"/chtc/PUBLIC/hzhao292/ImageNetMini/train\"\n",
    "dev_valfile_path = \"/chtc/PUBLIC/hzhao292/ImageNetMini/val\"\n",
    "\n",
    "# Define the transformer.\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  # Ensure ToTensor is included\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),  # Ensure ToTensor is included\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a class `RemoteImageFolder` inherit from `VisionDataset`. It does the same function as `ImageFolder` in pyTorch, but accept remote data source. It's also compatible with local path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_loader, val_loader):\n",
    "\n",
    "    model = models.vgg16(pretrained=True)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = 5\n",
    "\n",
    "    print(\"Training started.\")\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(val_loader.dataset)\n",
    "        accuracy = correct / total\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {epoch_loss:.2f}, Accuracy: {accuracy:.2f}, Time Taken: {time_taken:.2f} seconds\")\n",
    "    print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with reading data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Read Locally.\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_dataset = RemoteImageFolder(root=local_trainfile_path, transform=train_transforms)\n",
    "val_dataset = RemoteImageFolder(root=local_valfile_path, transform=val_transforms)\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Data preparing time: {end_time-start_time:4f}.\")\n",
    "training(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with reading data remotely using pelicanfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Read data remotely from Pelican\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "fs = PelicanFileSystem(\"pelican://osg-htc.org\")\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = RemoteImageFolder(root=dev_trainfile_path,fs=fs,transform=train_transforms)\n",
    "val_dataset = RemoteImageFolder(root=dev_valfile_path,fs=fs,transform=val_transforms)\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Data preparing time: {end_time-start_time:4f}.\")\n",
    "\n",
    "training(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with reading data remotely using pelicanfs, adding local cache "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Read data remotely from Pelican with local Cache\")\n",
    "\n",
    "start_time = time.time()\n",
    "# Load the datasets\n",
    "fs = fsspec.filesystem(\"filecache\", target_protocol='osdf', cache_storage='tmp/files/')\n",
    "train_dataset = RemoteImageFolder(root=dev_trainfile_path, fs=fs, transform=train_transforms)\n",
    "val_dataset = RemoteImageFolder(root=dev_valfile_path, fs=fs, transform=val_transforms)\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "end_time = time.time()\n",
    "print(f\"Data preparing time: {end_time-start_time:4f}.\")\n",
    "\n",
    "training(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading zip file using pelicanfs first, then unzip and train locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading zip file from pelican first, extract and train on it.\")\n",
    "time1 = time.time()\n",
    "print(\"Downloading ImageNetMini.zip\")\n",
    "fs = PelicanFileSystem(\"pelican://osg-htc.org\")\n",
    "fs.get(\"/chtc/PUBLIC/hzhao292/ImageNetMini.zip\",\"./\")\n",
    "time2 = time.time()\n",
    "print(f\"  - Time used: {time2-time1:2f}.\",)\n",
    "\n",
    "\n",
    "print(\"Extracting ImageNetMini.zip\")\n",
    "file = zipfile.ZipFile('ImageNetMini.zip')\n",
    "file.extractall('./data')\n",
    "time3 = time.time()\n",
    "print(f\"  - Time used: {time3-time2:2f}.\",)\n",
    "\n",
    "trainfile_path = \"./data/ImageNetMini/train/\"\n",
    "valfile_path = \"./data/ImageNetMini/val/\"\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = RemoteImageFolder(root=trainfile_path, transform=train_transforms)\n",
    "val_dataset = RemoteImageFolder(root=valfile_path, transform=val_transforms)\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "time4 = time.time()\n",
    "print(f\"Data preparing time: {time4-time3:2f}.\")\n",
    "\n",
    "training(train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
