{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5da88a8",
   "metadata": {},
   "source": [
    "# Dataloading benchmarking using Fashion-MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f229e8a6",
   "metadata": {},
   "source": [
    "We are using [Fashion-MNIST](https://www.kaggle.com/datasets/zalando-research/fashionmnist) dataset for benchmarking our datapipe performance.\n",
    "\n",
    "Model is from this [kaggle notebook](https://www.kaggle.com/code/pankajj/fashion-mnist-with-pytorch-93-accuracy)\n",
    "\n",
    "## Dataset Size:\n",
    "| Size       | File Size | Zipped size |\n",
    "|:-----------|:----------|:-----------------|\n",
    "| Train data | 127M      | 33M              |\n",
    "| Test data  | 22M       | 5.4M             |\n",
    "\n",
    "\n",
    "The benchmark results were run using a MacBook Pro 2021 equipped with a chip Apple M1 Pro and 16 GB of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c3176",
   "metadata": {},
   "source": [
    "# Section1 : Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe82d25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:39:27.452114Z",
     "iopub.status.busy": "2024-07-31T19:39:27.451258Z",
     "iopub.status.idle": "2024-07-31T19:39:30.231923Z",
     "shell.execute_reply": "2024-07-31T19:39:30.229802Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import time\n",
    "import fsspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pelicanfs.core import PelicanFileSystem\n",
    "from zipfile import ZipFile \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d46134",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97dc302d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:39:30.239792Z",
     "iopub.status.busy": "2024-07-31T19:39:30.239201Z",
     "iopub.status.idle": "2024-07-31T19:39:30.506458Z",
     "shell.execute_reply": "2024-07-31T19:39:30.505245Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class FashionDataset(Dataset):  \n",
    "    def __init__(self, data, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.fashion_MNIST = list(data.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "        label = []\n",
    "        image = []\n",
    "        \n",
    "        for i in self.fashion_MNIST:\n",
    "             # first column is of labels.\n",
    "            label.append(i[0])\n",
    "            image.append(i[1:])\n",
    "        self.labels = np.asarray(label)\n",
    "        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "class FashionCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FashionCNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
    "        self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bfe7730",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:39:30.513525Z",
     "iopub.status.busy": "2024-07-31T19:39:30.513222Z",
     "iopub.status.idle": "2024-07-31T19:39:30.523660Z",
     "shell.execute_reply": "2024-07-31T19:39:30.522916Z"
    }
   },
   "outputs": [],
   "source": [
    "def training():\n",
    "    num_epochs = 3\n",
    "    count = 0\n",
    "    # Lists for visualization of loss and accuracy \n",
    "    loss_list = []\n",
    "    iteration_list = []\n",
    "    accuracy_list = []\n",
    "\n",
    "    # Lists for knowing classwise accuracy\n",
    "    predictions_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        for images, labels in train_loader:\n",
    "            # Transfering images and labels to GPU if available\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "            # Use the actual batch size when reshaping\n",
    "            batch_size = images.size(0)  # Get the current batch size\n",
    "            train = Variable(images.view(batch_size, 1, 28, 28))\n",
    "        \n",
    "            # Forward pass \n",
    "            outputs = model(train)\n",
    "            loss = error(outputs, labels)\n",
    "        \n",
    "            # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            #Propagating the error backward\n",
    "            loss.backward()\n",
    "        \n",
    "            # Optimizing the parameters\n",
    "            optimizer.step()\n",
    "    \n",
    "            count += 1\n",
    "    \n",
    "            # Testing\n",
    "            if not (count % 50):    # It's same as \"if count % 50 == 0\"\n",
    "                total = 0\n",
    "                correct = 0\n",
    "        \n",
    "                for images, labels in test_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    labels_list.append(labels)\n",
    "                    \n",
    "                    batch_size = images.size(0)\n",
    "                    test = Variable(images.view(batch_size, 1, 28, 28))\n",
    "            \n",
    "                    outputs = model(test)\n",
    "            \n",
    "                    predictions = torch.max(outputs, 1)[1].to(device)\n",
    "                    predictions_list.append(predictions)\n",
    "                    correct += (predictions == labels).sum()\n",
    "            \n",
    "                    total += len(labels)\n",
    "            \n",
    "                accuracy = correct * 100 / total\n",
    "                loss_list.append(loss.data)\n",
    "                iteration_list.append(count)\n",
    "                accuracy_list.append(accuracy)\n",
    "        \n",
    "        if not (count % 500):\n",
    "            print(\"Iteration: {}, Loss: {:.2f}, Accuracy: {:2f}%\".format(count, loss.data, accuracy))\n",
    "        end_time = time.time()\n",
    "        print(f\"Time of {epoch+1}/{num_epochs} epoch: {end_time-start_time:.2f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c2fd65",
   "metadata": {},
   "source": [
    "## Read from Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74689e26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:39:30.530496Z",
     "iopub.status.busy": "2024-07-31T19:39:30.530262Z",
     "iopub.status.idle": "2024-07-31T19:40:25.612793Z",
     "shell.execute_reply": "2024-07-31T19:40:25.611492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing before training: 4.46\n",
      "Time of 1/3 epoch: 144.34s.\n",
      "Time of 2/3 epoch: 133.69s.\n",
      "Time of 3/3 epoch: 145.90s.\n"
     ]
    }
   ],
   "source": [
    "s_time = time.time()\n",
    "\n",
    "train_csv = pd.read_csv(\"input/fashion-mnist_train.csv\")\n",
    "test_csv = pd.read_csv(\"input/fashion-mnist_test.csv\")\n",
    "\n",
    "train_set = FashionDataset(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128)\n",
    "test_loader = DataLoader(train_set, batch_size=128)\n",
    "\n",
    "e_time = time.time()\n",
    "\n",
    "print(f\"Preparing before training: {e_time - s_time:.2f}\")\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea20425",
   "metadata": {},
   "source": [
    "## Read from Pelican using Pelicanfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "140143c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:40:25.619691Z",
     "iopub.status.busy": "2024-07-31T19:40:25.619187Z",
     "iopub.status.idle": "2024-07-31T19:41:19.330318Z",
     "shell.execute_reply": "2024-07-31T19:41:19.328781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing before training: 8.83\n",
      "Time of 1/3 epoch: 133.68s.\n",
      "Time of 2/3 epoch: 135.55s.\n",
      "Time of 3/3 epoch: 149.93s.\n"
     ]
    }
   ],
   "source": [
    "s_time = time.time()\n",
    "\n",
    "fs = PelicanFileSystem(\"pelican://osg-htc.org\")\n",
    "train_csv = pd.read_csv(fs.open('/chtc/PUBLIC/hzhao292/fashion-mnist_train.csv', 'rb'))\n",
    "test_csv = pd.read_csv(fs.open('/chtc/PUBLIC/hzhao292/fashion-mnist_test.csv', 'rb'))\n",
    "\n",
    "train_set = FashionDataset(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128)\n",
    "test_loader = DataLoader(train_set, batch_size=128)\n",
    "\n",
    "e_time = time.time()\n",
    "\n",
    "print(f\"Preparing before training: {e_time - s_time:.2f}\")\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3292d4",
   "metadata": {},
   "source": [
    "# Reading from Pelican with local cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9dd88d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:41:19.337346Z",
     "iopub.status.busy": "2024-07-31T19:41:19.336879Z",
     "iopub.status.idle": "2024-07-31T19:42:12.545938Z",
     "shell.execute_reply": "2024-07-31T19:42:12.543414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing before training: 8.44\n",
      "Time of 1/3 epoch: 150.61s.\n",
      "Time of 2/3 epoch: 141.30s.\n",
      "Time of 3/3 epoch: 169.34s.\n"
     ]
    }
   ],
   "source": [
    "s_time = time.time()\n",
    "\n",
    "fs = fsspec.filesystem(\"filecache\", target_protocol='osdf', cache_storage='tmp/files/')\n",
    "\n",
    "train_csv = pd.read_csv(fs.open('/chtc/PUBLIC/hzhao292/fashion-mnist_train.csv', 'rb'))\n",
    "test_csv = pd.read_csv(fs.open('/chtc/PUBLIC/hzhao292/fashion-mnist_test.csv', 'rb'))\n",
    "\n",
    "train_set = FashionDataset(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128)\n",
    "test_loader = DataLoader(train_set, batch_size=128)\n",
    "\n",
    "e_time = time.time()\n",
    "\n",
    "print(f\"Preparing before training: {e_time - s_time:.2f}\")\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06603101",
   "metadata": {},
   "source": [
    "# Downloading zip file from pelican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ce89c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:42:12.555064Z",
     "iopub.status.busy": "2024-07-31T19:42:12.554045Z",
     "iopub.status.idle": "2024-07-31T19:43:05.815717Z",
     "shell.execute_reply": "2024-07-31T19:43:05.814257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing before training: 6.27\n",
      "Time of 1/3 epoch: 151.06s.\n",
      "Time of 2/3 epoch: 124.90s.\n",
      "Time of 3/3 epoch: 133.65s.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "s_time = time.time()\n",
    "\n",
    "fs = PelicanFileSystem(\"pelican://osg-htc.org\")\n",
    "\n",
    "def read_csv_from_zipped(fs, path):\n",
    "    # Read the zip file from Pelican into a BytesIO buffer\n",
    "    with fs.open(path, 'rb') as file:\n",
    "        zip_buffer = BytesIO(file.read())\n",
    "\n",
    "    # Create a ZipFile object from the buffer\n",
    "    with zipfile.ZipFile(zip_buffer, 'r') as zipf:\n",
    "        csv_file_name = zipf.namelist()[0]\n",
    "        with zipf.open(csv_file_name) as csv_file:\n",
    "            # Read the CSV file content into a pandas DataFrame\n",
    "            df = pd.read_csv(csv_file)\n",
    "    return df\n",
    "\n",
    "train_csv = read_csv_from_zipped(fs, '/chtc/PUBLIC/hzhao292/fashion-mnist_train.zip')\n",
    "test_csv = read_csv_from_zipped(fs, '/chtc/PUBLIC/hzhao292/fashion-mnist_test.zip')\n",
    "\n",
    "train_set = FashionDataset(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128)\n",
    "test_loader = DataLoader(train_set, batch_size=128)\n",
    "\n",
    "e_time = time.time()\n",
    "\n",
    "print(f\"Preparing before training: {e_time - s_time:.2f}\")\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "190727b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:43:05.822226Z",
     "iopub.status.busy": "2024-07-31T19:43:05.821763Z",
     "iopub.status.idle": "2024-07-31T19:43:59.383742Z",
     "shell.execute_reply": "2024-07-31T19:43:59.382118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing before training: 6.37\n",
      "Time of 1/3 epoch: 125.07s.\n",
      "Time of 2/3 epoch: 123.13s.\n",
      "Time of 3/3 epoch: 135.19s.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "s_time = time.time()\n",
    "fs = PelicanFileSystem(\"pelican://osg-htc.org\")\n",
    "\n",
    "def stream_large_zip(fs, path):\n",
    "    with fsspec.open(path, 'rb') as file:\n",
    "        with zipfile.ZipFile(file) as zipf:\n",
    "            csv_file_name = zipf.namelist()[0]\n",
    "            with zipf.open(csv_file_name) as csv_file:\n",
    "                df = pd.read_csv(csv_file)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_csv = read_csv_from_zipped(fs, '/chtc/PUBLIC/hzhao292/fashion-mnist_train.zip')\n",
    "test_csv = read_csv_from_zipped(fs, '/chtc/PUBLIC/hzhao292/fashion-mnist_test.zip')\n",
    "\n",
    "train_set = FashionDataset(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128)\n",
    "test_loader = DataLoader(train_set, batch_size=128)\n",
    "\n",
    "e_time = time.time()\n",
    "\n",
    "print(f\"Preparing before training: {e_time - s_time:.2f}\")\n",
    "\n",
    "training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
